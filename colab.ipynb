{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zifeitong/little_learner/blob/main/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuiSPSDKYwW_"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import builtins\n",
        "\n",
        "# redefine map() to return a list\n",
        "def map(*args, **kwargs):\n",
        "  return list(builtins.map(*args, **kwargs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfeCojV3O1pr"
      },
      "outputs": [],
      "source": [
        "# Chapter 1\n",
        "\n",
        "def line(x):\n",
        "  return lambda theta: theta[0] * x + theta[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikhs8WDEQQhC"
      },
      "outputs": [],
      "source": [
        "# Chapter 2\n",
        "\n",
        "def is_scalar(tensor):\n",
        "  return isinstance(tensor, (int, float))\n",
        "\n",
        "class Tensor:\n",
        "  def __init__(self, elements):\n",
        "    self._elements = elements\n",
        "\n",
        "  def __getitem__(self, key):\n",
        "    return self._elements[key]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self._elements)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self._elements.__repr__()\n",
        "\n",
        "def rank(tensor):\n",
        "  if is_scalar(tensor):\n",
        "    return 0\n",
        "  else:\n",
        "    return rank(tensor[0]) + 1\n",
        "\n",
        "def shape(tensor):\n",
        "  if is_scalar(tensor):\n",
        "    return []\n",
        "  else:\n",
        "    return [len(tensor)] + shape(tensor[0])\n",
        "\n",
        "def equal(lhs, rhs):\n",
        "  if is_scalar(lhs) and is_scalar(rhs):\n",
        "    return lhs == rhs\n",
        "\n",
        "  if shape(lhs) != shape(rhs):\n",
        "    return False\n",
        "\n",
        "  for i in range(len(lhs._elements)):\n",
        "    if not equal(lhs._elements[i], rhs._elements[i]):\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "assert(rank(1) == 0)\n",
        "assert(rank(Tensor([0])) == 1)\n",
        "assert(shape(Tensor([0])) == [1])\n",
        "assert(rank(Tensor([Tensor([1, 2]), Tensor([3, 4])])) == 2)\n",
        "assert(shape(Tensor([Tensor([1, 2, 3]), Tensor([4, 5, 6])])) == [2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGW5vuDsRhnW"
      },
      "outputs": [],
      "source": [
        "# Interlude I\n",
        "\n",
        "def sum_1(tensor):\n",
        "  s = 0\n",
        "  for i in range(len(tensor)):\n",
        "    s += tensor[i]\n",
        "  return s\n",
        "\n",
        "def sum(tensor):\n",
        "  if rank(tensor) == 1:\n",
        "    return sum_1(tensor)\n",
        "  else:\n",
        "    return Tensor([sum(e) for e in tensor._elements])\n",
        "\n",
        "assert(\n",
        "    equal(sum(Tensor([Tensor([Tensor([1, 2, 3])]),\n",
        "                      Tensor([Tensor([4, 5, 6])])])),\n",
        "          Tensor([Tensor([6]), Tensor([15])])))\n",
        "assert(equal(sum(Tensor([Tensor([1, 2, 3]), Tensor([4, 5, 6])])),\n",
        "             Tensor([6, 15])))\n",
        "assert(equal(sum(Tensor([1, 2, 3])), 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvurjpNIXXxh"
      },
      "outputs": [],
      "source": [
        "# Chapter 3\n",
        "\n",
        "# From now on, using jnp.array as Tensor\n",
        "\n",
        "def l2_loss(target):\n",
        "  def expectant_func(xs, ys):\n",
        "    def obj_func(theta, unused_rev = None):\n",
        "      pred_ys = target(xs)(theta)\n",
        "      return jnp.sum((ys - pred_ys) ** 2)\n",
        "    return obj_func\n",
        "  return expectant_func\n",
        "\n",
        "xs = jnp.array([2.0, 1.0, 4.0, 3.0])\n",
        "ys = jnp.array([1.8, 1.2, 4.2, 3.3])\n",
        "assert(l2_loss(line)(xs, ys)([0, 0], 0) == 33.21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6uB-UFIe7ED"
      },
      "outputs": [],
      "source": [
        "# Chapter 4\n",
        "\n",
        "gradient_of = jax.grad\n",
        "\n",
        "assert(gradient_of(lambda theta: theta[0] * theta[0])([27.0]) == [54.0])\n",
        "assert(gradient_of(l2_loss(line)(xs, ys))([0.0, 0.0]) == [-63.0, -21.0])\n",
        "\n",
        "def revise(f, revs, theta):\n",
        "  for i in range(revs):\n",
        "    theta = f(theta, i)\n",
        "  return theta\n",
        "\n",
        "revs = 1000\n",
        "alpha = 0.01\n",
        "def gradient_descent(obj, theta):\n",
        "  def f(big_theta, unused_rev = None):\n",
        "    return map(lambda p, g: p - alpha * g,\n",
        "               big_theta,\n",
        "               gradient_of(obj)(big_theta))\n",
        "  return revise(jax.jit(f), revs, theta)\n",
        "\n",
        "big_theta = gradient_descent(l2_loss(line)(xs, ys), [0.0, 0.0])\n",
        "assert jnp.isclose(big_theta[0], 1.05)\n",
        "assert jnp.isclose(big_theta[1], 1.87e-6, atol=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjpFKVSHE8p4"
      },
      "outputs": [],
      "source": [
        "# Interlude II\n",
        "\n",
        "import contextvars\n",
        "\n",
        "class _HyperParameter():\n",
        "  def __init__(self, parameter, value):\n",
        "    self._parameter = parameter\n",
        "    self._value = value\n",
        "\n",
        "  def __enter__(self):\n",
        "    self._token = self._parameter.set(self._value)\n",
        "\n",
        "  def __exit__(self, type, value, traceback):\n",
        "    self._parameter.reset(self._token)\n",
        "\n",
        "def declare_hypers(name):\n",
        "  return contextvars.ContextVar(name)\n",
        "\n",
        "def hypers(parameter, value):\n",
        "  return _HyperParameter(parameter, value)\n",
        "\n",
        "smaller = declare_hypers('smaller')\n",
        "larger = declare_hypers('larger')\n",
        "\n",
        "with hypers(smaller, 1), hypers(larger, 2):\n",
        "  assert(smaller.get() == 1)\n",
        "  assert(larger.get() == 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCSe59LGJMko"
      },
      "outputs": [],
      "source": [
        "# Chapter 5\n",
        "\n",
        "revs = declare_hypers('revs')\n",
        "alpha = declare_hypers('alpha')\n",
        "\n",
        "def gradient_descent(obj, theta):\n",
        "  def f(big_theta, rev):\n",
        "    return map(lambda p, g: p - alpha.get() * g,\n",
        "               big_theta,\n",
        "               gradient_of(obj)(big_theta, rev))\n",
        "  return revise(jax.jit(f), revs.get(), theta)\n",
        "\n",
        "quad_xs = jnp.array([-1.0, 0.0, 1.0, 2.0, 3.0])\n",
        "quad_ys = jnp.array([2.55, 2.1, 4.35, 10.2, 18.25])\n",
        "\n",
        "def quad(x):\n",
        "  return lambda theta: theta[0] * (x ** 2) + theta[1] * x + theta[2]\n",
        "\n",
        "with hypers(revs, 1000), hypers(alpha, 0.001):\n",
        "  big_theta = gradient_descent(l2_loss(quad)(quad_xs, quad_ys), [0.0, 0.0, 0.0])\n",
        "  assert jnp.isclose(big_theta[0], 1.48, rtol=1e-2)\n",
        "  assert jnp.isclose(big_theta[1], 0.99, rtol=1e-2)\n",
        "  assert jnp.isclose(big_theta[2], 2.05, rtol=1e-2)\n",
        "\n",
        "plane_xs = jnp.array([[1.0, 2.05], [1.0, 3.0], [2.0, 2.0], [2.0, 3.91], [3.0, 6.13], [4.0, 8.09]])\n",
        "plane_ys = jnp.array([13.99, 15.99, 18.0, 22.4, 30.2, 37.94])\n",
        "\n",
        "def plane(t):\n",
        "  return lambda theta: jnp.dot(t, theta[0]) + theta[1]\n",
        "\n",
        "with hypers(revs, 1000), hypers(alpha, 0.001):\n",
        "  big_theta = gradient_descent(l2_loss(plane)(plane_xs, plane_ys), [jnp.array([0.0, 0.0]), 0.0])\n",
        "  assert jnp.isclose(big_theta[0][0], 3.98, rtol=1e-1)\n",
        "  assert jnp.isclose(big_theta[0][1], 2.04, rtol=1e-1)\n",
        "  assert jnp.isclose(big_theta[1], 5.78, rtol=1e-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1PsgFJpO0-Y"
      },
      "outputs": [],
      "source": [
        "# Chapter 6\n",
        "\n",
        "batch_size = declare_hypers('batch_size')\n",
        "\n",
        "def samples(n, s, key):\n",
        "  return jax.random.choice(key, jnp.arange(0, n), [s])\n",
        "\n",
        "def sampling_obj(expectant, xs, ys, key):\n",
        "  def obj(theta, rev):\n",
        "    n = len(xs)\n",
        "    b = samples(n, batch_size.get(), jax.random.fold_in(key, rev))\n",
        "    return expectant(xs[b], ys[b])(theta)\n",
        "  return obj\n",
        "\n",
        "with hypers(revs, 15000), hypers(alpha, 0.001), hypers(batch_size, 4):\n",
        "  big_theta = gradient_descent(\n",
        "      sampling_obj(l2_loss(plane), plane_xs, plane_ys, jax.random.key(42)),\n",
        "       [jnp.array([0.0, 0.0]), 0.0])\n",
        "  assert jnp.isclose(big_theta[0][0], 3.98, rtol=1e-1)\n",
        "  assert jnp.isclose(big_theta[0][1], 1.97, rtol=1e-1)\n",
        "  assert jnp.isclose(big_theta[1], 6.16, rtol=1e-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2CbRJ3EY8b7"
      },
      "outputs": [],
      "source": [
        "# Chapter 7\n",
        "\n",
        "def try_plane(a_gradient_decent):\n",
        "  with hypers(revs, 15000), hypers(alpha, 0.001), hypers(batch_size, 4):\n",
        "    big_theta = a_gradient_decent(\n",
        "        sampling_obj(l2_loss(plane), plane_xs, plane_ys, jax.random.key(42)),\n",
        "        [jnp.array([0.0, 0.0]), 0.0])\n",
        "    assert jnp.isclose(big_theta[0][0], 3.98, rtol=0.1)\n",
        "    assert jnp.isclose(big_theta[0][1], 1.97, rtol=0.1)\n",
        "    assert jnp.isclose(big_theta[1], 6.16, rtol=0.1)\n",
        "\n",
        "def gradient_descent(inflate, deflate, update):\n",
        "  def _gradient_descent(obj, theta):\n",
        "    def f(big_theta, rev):\n",
        "      return map(update,\n",
        "                 big_theta,\n",
        "                 gradient_of(obj)(map(deflate, big_theta), rev))\n",
        "    return map(deflate, revise(jax.jit(f), revs.get(), map(inflate, theta)))\n",
        "  return _gradient_descent\n",
        "\n",
        "def naked_i(p):\n",
        "  big_p = p\n",
        "  return big_p\n",
        "\n",
        "def naked_d(big_p):\n",
        "  p = big_p\n",
        "  return p\n",
        "\n",
        "def naked_u(big_p, g):\n",
        "  p = big_p\n",
        "  return p - alpha.get() * g\n",
        "\n",
        "naked_gradient_descent = gradient_descent(naked_i, naked_d, naked_u)\n",
        "\n",
        "try_plane(naked_gradient_descent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9lFV7vyqaU9"
      },
      "outputs": [],
      "source": [
        "# Chapter 8\n",
        "\n",
        "mu = declare_hypers('mu')\n",
        "\n",
        "def velocity_i(p):\n",
        "  if is_scalar(p):\n",
        "    return [p, 0.0]\n",
        "  return [p, jnp.zeros(p.shape)]\n",
        "\n",
        "def velocity_d(big_p):\n",
        "  return big_p[0]\n",
        "\n",
        "def velocity_u(big_p, g):\n",
        "  v = mu.get() * big_p[1] - alpha.get() * g\n",
        "  return [big_p[0] + v, v]\n",
        "\n",
        "velocity_gradient_descent = gradient_descent(velocity_i, velocity_d, velocity_u)\n",
        "\n",
        "def try_plane(a_gradient_decent, a_revs):\n",
        "  with hypers(revs, a_revs), hypers(alpha, 0.001), hypers(batch_size, 4):\n",
        "    key = jax.random.key(42)\n",
        "    big_theta = a_gradient_decent(\n",
        "        sampling_obj(l2_loss(plane), plane_xs, plane_ys, key),\n",
        "        [jnp.array([0.0, 0.0]), 0.0])\n",
        "    assert jnp.isclose(big_theta[0][0], 3.98, rtol=1e-1)\n",
        "    assert jnp.isclose(big_theta[0][1], 1.97, rtol=1e-1)\n",
        "    assert jnp.isclose(big_theta[1], 6.16, rtol=1e-1)\n",
        "\n",
        "with hypers(mu, 0.9):\n",
        "  try_plane(velocity_gradient_descent, 5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X4EISEhq9Uh"
      },
      "outputs": [],
      "source": [
        "# Interlude IV\n",
        "\n",
        "def smooth(decay_rate, average, g):\n",
        "  return decay_rate * average + (1 - decay_rate) * g\n",
        "\n",
        "assert jnp.isclose(smooth(0.9,\n",
        "                          jnp.array([0.82, 2.9, 2.28]),\n",
        "                          jnp.array([13.4, 18.2, 41.4])),\n",
        "                   jnp.array([2.08, 4.43, 6.19]), rtol=1e-1).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku30Mu0Ww18Q"
      },
      "outputs": [],
      "source": [
        "# Chapter 9\n",
        "\n",
        "beta = declare_hypers('beta')\n",
        "\n",
        "EPS = 1e-8\n",
        "\n",
        "def rms_u(big_p, g):\n",
        "  r = smooth(beta.get(), big_p[1], g ** 2)\n",
        "  alpha_hat = alpha.get() / (jnp.sqrt(r) + EPS)\n",
        "  return [big_p[0] - alpha_hat * g, r]\n",
        "\n",
        "def rms_i(p):\n",
        "  if is_scalar(p):\n",
        "    return [p, 0.0]\n",
        "  return [p, jnp.zeros(p.shape)]\n",
        "\n",
        "def rms_d(big_p):\n",
        "  return big_p[0]\n",
        "\n",
        "rms_gradient_descent = gradient_descent(rms_i, rms_d, rms_u)\n",
        "\n",
        "def try_plane(a_gradient_decent, a_revs, a_alpha):\n",
        "  with hypers(revs, a_revs), hypers(alpha, a_alpha), hypers(batch_size, 4):\n",
        "    big_theta = a_gradient_decent(\n",
        "        sampling_obj(l2_loss(plane), plane_xs, plane_ys, jax.random.key(42)),\n",
        "        [jnp.array([0.0, 0.0]), 0.0])\n",
        "    assert jnp.isclose(big_theta[0][0], 3.98, rtol=1e-1)\n",
        "    assert jnp.isclose(big_theta[0][1], 1.97, rtol=1e-1)\n",
        "    assert jnp.isclose(big_theta[1], 6.16, rtol=1e-1)\n",
        "\n",
        "with hypers(beta, 0.9):\n",
        "  try_plane(rms_gradient_descent, 3000, 0.01)\n",
        "\n",
        "def adam_u(big_p, g):\n",
        "  r = smooth(beta.get(), big_p[2], g ** 2)\n",
        "  alpha_hat = alpha.get() / (jnp.sqrt(r) + EPS)\n",
        "  v = smooth(mu.get(), big_p[1], g)\n",
        "  return [big_p[0] - alpha_hat * v, v, r]\n",
        "\n",
        "def adam_i(p):\n",
        "  if is_scalar(p):\n",
        "    return [p, 0.0, 0.0]\n",
        "  return [p, jnp.zeros(p.shape), jnp.zeros(p.shape)]\n",
        "\n",
        "def adam_d(big_p):\n",
        "  return big_p[0]\n",
        "\n",
        "adam_gradient_descent = gradient_descent(adam_i, adam_d, adam_u)\n",
        "\n",
        "with hypers(mu, 0.85), hypers(beta, 0.9):\n",
        "  try_plane(rms_gradient_descent, 1500, 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HLVoipV2Rax"
      },
      "outputs": [],
      "source": [
        "# Interlude V\n",
        "\n",
        "import math\n",
        "\n",
        "def tmap(f, *args):\n",
        "  return jax.vmap(f)(*args)\n",
        "\n",
        "def is_scalar(t):\n",
        "  return isinstance(t, (int, float)) or t.shape == ()\n",
        "\n",
        "def is_of_rank(n, t):\n",
        "  if n == 0:\n",
        "    return is_scalar(t)\n",
        "  elif is_scalar(t):\n",
        "    return False\n",
        "  else:\n",
        "    return is_of_rank(n-1, t[0])\n",
        "\n",
        "def ext_1(f, n):\n",
        "  return lambda t: f(t) if is_of_rank(n, t) else tmap(ext_1(f, n), t)\n",
        "\n",
        "sqrt_0 = jnp.sqrt\n",
        "\n",
        "sqrt = ext_1(sqrt_0, 0)\n",
        "zeros = ext_1(lambda x: 0.0, 0)\n",
        "sum = ext_1(sum_1, 1)\n",
        "flatten = ext_1(jnp.ravel, 2)\n",
        "\n",
        "def rank_gt(t, u):\n",
        "  if is_scalar(t):\n",
        "    return False\n",
        "  elif is_scalar(u):\n",
        "    return True\n",
        "  else:\n",
        "    return rank_gt(t[0], u[0])\n",
        "\n",
        "def is_of_ranks(n, t, m, u):\n",
        "  if is_of_rank(n, t):\n",
        "    return is_of_rank(m, u)\n",
        "  return False\n",
        "\n",
        "def desc_t(g, t, u):\n",
        "  return tmap(lambda et: g(et, u), t)\n",
        "\n",
        "def desc_u(g, t, u):\n",
        "  return tmap(lambda eu: g(t, eu), u)\n",
        "\n",
        "def desc(g, n, t, m, u):\n",
        "  if is_of_rank(n, t):\n",
        "    return desc_u(g, t, u)\n",
        "  elif is_of_rank(m, u):\n",
        "    return desc_t(g, t, u)\n",
        "  elif len(t) == len(u):\n",
        "    return tmap(g, t, u)\n",
        "  elif rank_gt(t, u):\n",
        "    return desc_t(g, t, u)\n",
        "  else:\n",
        "    return desc_u(g, t, u)\n",
        "\n",
        "\n",
        "def ext_2(f, n, m):\n",
        "  return lambda t, u: f(t, u) if is_of_ranks(n, t, m, u) else desc(ext_2(f, n, m), n, t, m, u)\n",
        "\n",
        "import operator\n",
        "\n",
        "add = ext_2(operator.add, 0, 0)\n",
        "mul = ext_2(operator.mul, 0, 0)\n",
        "\n",
        "def sqr(t):\n",
        "  return mul(t, t)\n",
        "\n",
        "dot = ext_2(jnp.dot, 1, 1)\n",
        "\n",
        "assert jnp.array_equal(add(jnp.array([1, 2]), 3),\n",
        "                       jnp.array([4, 5]))\n",
        "assert jnp.array_equal(add(jnp.array([1, 2]), jnp.array([1, 2])),\n",
        "                       jnp.array([2, 4]))\n",
        "assert jnp.array_equal(sqr(jnp.array([1, 2])),\n",
        "                       jnp.array([1, 4]))\n",
        "assert jnp.array_equal(sqr(jnp.array([[1, 2], [3, 4]])),\n",
        "                       jnp.array([[1, 4], [9, 16]]))\n",
        "assert dot(jnp.array([1, 2]), jnp.array([1, 2])) == 5\n",
        "assert jnp.array_equal(dot(jnp.array([[1, 2], [3, 4]]), jnp.array([1, 2])),\n",
        "                       jnp.array([5, 11]))\n",
        "\n",
        "mul_2_1 = ext_2(mul, 2, 1)\n",
        "\n",
        "assert jnp.array_equal(mul(jnp.array([[3, 4, 5], [7, 8, 9]]),\n",
        "                           jnp.array([2, 4, 3])),\n",
        "                       jnp.array([[6, 16, 15], [14, 32, 27]]))\n",
        "assert jnp.array_equal(mul_2_1(jnp.array([[3, 4, 5], [7, 8, 9]]),\n",
        "                               jnp.array([2, 4, 3])),\n",
        "                       jnp.array([[6, 16, 15], [14, 32, 27]]))\n",
        "assert jnp.array_equal(mul(jnp.array([[8, 1], [7, 3], [5, 4]]),\n",
        "                           jnp.array([[6, 2], [4, 9], [3, 8]])),\n",
        "                       jnp.array([[48, 2], [28, 27], [15, 32]]))\n",
        "assert jnp.array_equal(mul_2_1(jnp.array([[8, 1], [7, 3], [5, 4]]),\n",
        "                               jnp.array([[6, 2], [4, 9], [3, 8]])),\n",
        "                       jnp.array([[[48, 2], [42, 6], [30, 8]],\n",
        "                                  [[32, 9], [28, 27], [20, 36]],\n",
        "                                  [[24, 8], [21, 24], [15, 32]]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmze6fblKCOR"
      },
      "outputs": [],
      "source": [
        "# Chapter 10\n",
        "\n",
        "import jax.lax as lax\n",
        "\n",
        "def rectify_0(s):\n",
        "  return lax.cond(s < 0.0, lambda _: 0.0, lambda x: x, s)\n",
        "\n",
        "rectify = ext_1(rectify_0, 0)\n",
        "\n",
        "def linear_1_1(t):\n",
        "  return lambda theta: theta[0].dot(t) + theta[1]\n",
        "\n",
        "def relu_1_1(t):\n",
        "  return lambda theta: rectify(linear_1_1(t)(theta))\n",
        "\n",
        "assert relu_1_1(jnp.array([2.0, 1.0, 3.0]))([jnp.array([7.1, 4.3, -6.4]), 0.6]) == 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2A6UaXiKcDjd"
      },
      "outputs": [],
      "source": [
        "# Chapter 11\n",
        "\n",
        "def dot_2_1(w, t):\n",
        "  return sum(mul_2_1(w, t))\n",
        "\n",
        "def linear(t):\n",
        "  return lambda theta: dot_2_1(theta[0], t) + theta[1]\n",
        "\n",
        "def relu(t):\n",
        "  return lambda theta: rectify(linear(t)(theta))\n",
        "\n",
        "def k_relu(k):\n",
        "  return lambda t: lambda theta: t if k == 0 else k_relu(k-1)(relu(t)(theta))(theta[2:])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chapter 12\n",
        "\n",
        "def block(fn, shape_list):\n",
        "  return [fn, shape_list]\n",
        "\n",
        "def block_fn(ba):\n",
        "  return ba[0]\n",
        "\n",
        "def block_ls(ba):\n",
        "  return ba[1]\n",
        "\n",
        "def dense_block(n, m):\n",
        "  return block(relu, [[m, n], [m]])\n",
        "\n",
        "layer1 = dense_block(32, 64)\n",
        "layer2 = dense_block(64, 45)\n",
        "layer3 = dense_block(45, 26)\n",
        "\n",
        "def block_compose(f, g, j):\n",
        "  return lambda t: lambda theta: g(f(t)(theta))(theta[j:])\n",
        "\n",
        "def stack_2(ba, bb):\n",
        "  return block(block_compose(block_fn(ba), block_fn(bb), len(block_ls(ba))),\n",
        "               block_ls(ba) + block_ls(bb))\n",
        "\n",
        "def stacked_blocks(rbls, ba):\n",
        "  if not rbls:\n",
        "    return ba\n",
        "  else:\n",
        "    return stacked_blocks(rbls[1:], stack_2(ba, rbls[0]))\n",
        "\n",
        "def stack_blocks(bls):\n",
        "  return stacked_blocks(bls[1:], bls[0])\n",
        "\n",
        "three_layer_network = stack_blocks([layer1, layer2, layer3])"
      ],
      "metadata": {
        "id": "RsbZujfzezvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chapter 13\n",
        "\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "iris_train_xs = jnp.concat(\n",
        "    [iris['data'][0:45],  iris['data'][50:95],  iris['data'][100:145]])\n",
        "iris_test_xs = jnp.concat(\n",
        "    [iris['data'][45:50], iris['data'][95:100], iris['data'][145:150]])\n",
        "iris_train_ys = jax.nn.one_hot(jnp.concat(\n",
        "    [iris['target'][0:45],  iris['target'][50:95],  iris['target'][100:145]]), 3)\n",
        "iris_test_ys = jax.nn.one_hot(jnp.concat(\n",
        "    [iris['target'][45:50], iris['target'][95:100], iris['target'][145:150]]), 3)\n",
        "\n",
        "iris_network = stack_blocks([dense_block(4, 8), dense_block(8, 3)])\n",
        "\n",
        "def random_tensor(c, v, s, key):\n",
        "   return c + jax.random.normal(key, shape=s) * sqrt(v)\n",
        "\n",
        "def init_shape(s, key):\n",
        "  if len(s) == 1:\n",
        "    return jnp.zeros(s)\n",
        "  elif len(s) == 2:\n",
        "    return random_tensor(0.0, 2.0 / s[1], s, key)\n",
        "\n",
        "def init_theta(shapes, key):\n",
        "  key, *keys = jax.random.split(key, num=len(shapes) + 1)\n",
        "  return map(init_shape, shapes, keys)\n",
        "\n",
        "iris_classifer = block_fn(iris_network)\n",
        "iris_theta_shapes = block_ls(iris_network)\n",
        "\n",
        "# From https://github.com/themetaschemer/malt/blob/4fee9a6b70146058bf253dbadaae1eff3681ccbe/examples/iris.rkt#L94\n",
        "iris_initial_theta = [\n",
        "    jnp.array(\n",
        "        [[0.4567374693020529, 0.19828623224159106, -0.1791656741530271, -0.3010909419105787],\n",
        "        [-0.6085978529055036, -0.37813256632159414, 0.6525919461799214, -0.02736258427588277],\n",
        "        [-0.15910077091878255, 0.30935100240945007, -0.43223348220649294, 0.44424201464211593],\n",
        "        [ 0.29780171646282, 0.27115067507001933, 0.3512802108530173, -0.941133353767241],\n",
        "        [-0.6435366194048697, -0.7870457121505098, 0.4672028162559846, -0.4060316748060222],\n",
        "        [ 0.3542366127804169, -0.6294805381631496, 1.2119983516222874, -0.48964923866459675],\n",
        "        [ 0.29072501026246134, -0.11992778583131615, 0.2716865689059567, 0.5051197463327993],\n",
        "        [-0.05677192201680251, -0.8933344786252218, 0.10639004770659627, -0.7276129460870265]]),\n",
        "    jnp.array([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
        "    jnp.array(\n",
        "        [[0.8360463658942785, 0.21163937440648464, -0.36559830767572854, 0.34006155051045595,\n",
        "           0.3095265146359776, -0.1585941540367561, 0.33268716624682165, -0.5114119488395097],\n",
        "        [0.15466255181586858, -0.26658077790718954, 0.04571706722376748, 0.10422918798466209,\n",
        "           -0.17593682447129064, 0.6075530713389936, 0.007216798991190192, -0.4698148147112468],\n",
        "        [0.06636510408180833, -0.11501406598247131, 0.7855953481117244, 0.00849992094421447,\n",
        "           0.10415852852056427, 0.4557511137599346, -0.029003952783791656, 1.1873084795704665]]),\n",
        "    jnp.array([0., 0., 0.])]\n",
        "\n",
        "with hypers(revs, 2000), hypers(alpha, 0.0002), hypers(batch_size, 8):\n",
        "  iris_theta = naked_gradient_descent(\n",
        "      sampling_obj(l2_loss(iris_classifer), iris_train_xs, iris_train_ys, jax.random.key(42)),\n",
        "      iris_initial_theta)\n",
        "\n",
        "def model(target, theta):\n",
        "  return lambda t: target(t)(theta)\n",
        "\n",
        "iris_model = model(iris_classifer, iris_theta)"
      ],
      "metadata": {
        "id": "KSn8AptDj9b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interlude VI\n",
        "import itertools\n",
        "import contextlib\n",
        "\n",
        "def next_a(t, i, a):\n",
        "  return jnp.where(t[i] > t[a], i, a)\n",
        "\n",
        "def argmaxed(t, i, a):\n",
        "  a_hat = next_a(t, i, a)\n",
        "  if i == 0:\n",
        "    return a_hat\n",
        "  else:\n",
        "    return argmaxed(t, i-1, a_hat)\n",
        "\n",
        "def argmax_1(t):\n",
        "  i = len(t) - 1\n",
        "  return argmaxed(t, i, i)\n",
        "\n",
        "def class_eq_1(t, u):\n",
        "  return jnp.where(argmax_1(t) == argmax_1(u), 1.0, 0.0)\n",
        "\n",
        "class_eq = ext_2(class_eq_1, 1, 1)\n",
        "\n",
        "def accuracy(a_model, xs, ys):\n",
        "  return sum(class_eq(a_model(xs), ys)) / len(xs)\n",
        "\n",
        "assert accuracy(iris_model, iris_test_xs, iris_test_ys) == 1.0\n",
        "\n",
        "def grid_search(hyper_vals, f):\n",
        "  for prod in itertools.product(*map(lambda e: e[1], hyper_vals)):\n",
        "    with contextlib.ExitStack() as stack:\n",
        "      for var, val in zip(hyper_vals, prod):\n",
        "        stack.enter_context(hypers(var[0], val))\n",
        "      f()\n",
        "\n",
        "def find_iris_theta():\n",
        "  iris_theta = naked_gradient_descent(\n",
        "      sampling_obj(l2_loss(iris_classifer), iris_train_xs, iris_train_ys, jax.random.key(42)),\n",
        "      iris_initial_theta)\n",
        "  iris_model = model(iris_classifer, iris_theta)\n",
        "  print(f\"rev: {revs.get()}, alpha: {alpha.get()}, batch_size: {batch_size.get()}, accuracy:\",\n",
        "        accuracy(iris_model, iris_test_xs, iris_test_ys))\n",
        "\n",
        "grid_search([(revs,       [500, 1000, 2000, 4000]),\n",
        "             (alpha,      [0.0001, 0.0002, 0.0005]),\n",
        "             (batch_size, [4, 8, 16])],\n",
        "            find_iris_theta)"
      ],
      "metadata": {
        "id": "zNA0kqES9gA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2eb89f6-1b0b-46f0-c69b-2cad85e9a55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rev: 500, alpha: 0.0001, batch_size: 4, accuracy: 0.6666667\n",
            "rev: 500, alpha: 0.0001, batch_size: 8, accuracy: 0.6666667\n",
            "rev: 500, alpha: 0.0001, batch_size: 16, accuracy: 0.8\n",
            "rev: 500, alpha: 0.0002, batch_size: 4, accuracy: 0.8\n",
            "rev: 500, alpha: 0.0002, batch_size: 8, accuracy: 0.8\n",
            "rev: 500, alpha: 0.0002, batch_size: 16, accuracy: 0.93333334\n",
            "rev: 500, alpha: 0.0005, batch_size: 4, accuracy: 1.0\n",
            "rev: 500, alpha: 0.0005, batch_size: 8, accuracy: 1.0\n",
            "rev: 500, alpha: 0.0005, batch_size: 16, accuracy: 1.0\n",
            "rev: 1000, alpha: 0.0001, batch_size: 4, accuracy: 0.93333334\n",
            "rev: 1000, alpha: 0.0001, batch_size: 8, accuracy: 0.93333334\n",
            "rev: 1000, alpha: 0.0001, batch_size: 16, accuracy: 1.0\n",
            "rev: 1000, alpha: 0.0002, batch_size: 4, accuracy: 1.0\n",
            "rev: 1000, alpha: 0.0002, batch_size: 8, accuracy: 1.0\n",
            "rev: 1000, alpha: 0.0002, batch_size: 16, accuracy: 1.0\n",
            "rev: 1000, alpha: 0.0005, batch_size: 4, accuracy: 1.0\n",
            "rev: 1000, alpha: 0.0005, batch_size: 8, accuracy: 1.0\n",
            "rev: 1000, alpha: 0.0005, batch_size: 16, accuracy: 1.0\n",
            "rev: 2000, alpha: 0.0001, batch_size: 4, accuracy: 1.0\n",
            "rev: 2000, alpha: 0.0001, batch_size: 8, accuracy: 1.0\n",
            "rev: 2000, alpha: 0.0001, batch_size: 16, accuracy: 1.0\n",
            "rev: 2000, alpha: 0.0002, batch_size: 4, accuracy: 1.0\n",
            "rev: 2000, alpha: 0.0002, batch_size: 8, accuracy: 1.0\n",
            "rev: 2000, alpha: 0.0002, batch_size: 16, accuracy: 1.0\n",
            "rev: 2000, alpha: 0.0005, batch_size: 4, accuracy: 1.0\n",
            "rev: 2000, alpha: 0.0005, batch_size: 8, accuracy: 1.0\n",
            "rev: 2000, alpha: 0.0005, batch_size: 16, accuracy: 1.0\n",
            "rev: 4000, alpha: 0.0001, batch_size: 4, accuracy: 1.0\n",
            "rev: 4000, alpha: 0.0001, batch_size: 8, accuracy: 1.0\n",
            "rev: 4000, alpha: 0.0001, batch_size: 16, accuracy: 1.0\n",
            "rev: 4000, alpha: 0.0002, batch_size: 4, accuracy: 1.0\n",
            "rev: 4000, alpha: 0.0002, batch_size: 8, accuracy: 1.0\n",
            "rev: 4000, alpha: 0.0002, batch_size: 16, accuracy: 1.0\n",
            "rev: 4000, alpha: 0.0005, batch_size: 4, accuracy: 1.0\n",
            "rev: 4000, alpha: 0.0005, batch_size: 8, accuracy: 1.0\n",
            "rev: 4000, alpha: 0.0005, batch_size: 16, accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chapter 14\n",
        "\n",
        "import functools\n",
        "import numpy as np\n",
        "\n",
        "def load_data(path, shape):\n",
        "  return jnp.array(np.loadtxt(path)).reshape(*shape)\n",
        "\n",
        "!git clone https://github.com/zifeitong/little_learner &> /dev/null\n",
        "\n",
        "morse_train_xs = load_data('little_learner/data/morse-train-xs', [5200, 16, 1]) - 0.5\n",
        "morse_train_ys = load_data('little_learner/data/morse-train-ys', [5200, 26])\n",
        "morse_test_xs = load_data('little_learner/data/morse-test-xs', [1040, 16, 1]) - 0.5\n",
        "morse_test_ys = load_data('little_learner/data/morse-test-ys', [1040, 26])\n",
        "\n",
        "def correlate_2_2(filter, signal):\n",
        "  output = jax.scipy.signal.correlate2d(signal, filter, mode=\"same\")\n",
        "  return output[:, (shape(output)[1] - 1) // 2]\n",
        "\n",
        "def correlate_3_2(filter_banks, signal):\n",
        "  return ext_2(correlate_2_2, 2, 2)(filter_banks, signal).transpose()\n",
        "\n",
        "correlate = ext_2(correlate_3_2, 3, 2)\n",
        "\n",
        "\n",
        "signal = jnp.array([\n",
        "    [1., 2.], [3., 4.], [5., 6.], [7., 8.], [9., 10.], [11., 12.]\n",
        "])\n",
        "\n",
        "filter_banks = jnp.array([\n",
        "    [[1., 2.], [3., 4.], [5., 6.]],\n",
        "    [[7., 8.], [9., 10.], [11., 12.]],\n",
        "    [[13., 14.], [15., 16.], [17., 18.]],\n",
        "    [[19., 20.], [21., 22.], [23., 24.]],\n",
        "])\n",
        "\n",
        "assert jnp.array_equal(\n",
        "    correlate_3_2(filter_banks, signal),\n",
        "    jnp.array([\n",
        "       [  50.,  110.,  170.,  230.],\n",
        "       [  91.,  217.,  343.,  469.],\n",
        "       [ 133.,  331.,  529.,  727.],\n",
        "       [ 175.,  445.,  715.,  985.],\n",
        "       [ 217.,  559.,  901., 1243.],\n",
        "       [ 110.,  362.,  614.,  866.]]))"
      ],
      "metadata": {
        "id": "VkjjDwiP3dQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chapter 15\n",
        "\n",
        "def corr(t):\n",
        "  return lambda theta: correlate(theta[0], t) + theta[1]\n",
        "\n",
        "def recu(t):\n",
        "  return lambda theta: rectify(corr(t)(theta))\n",
        "\n",
        "def recu_block(b, m, d):\n",
        "    return block(recu, [[b, m, d], [b]])\n",
        "\n",
        "sum_2 = sum_1\n",
        "\n",
        "sum_cols = ext_1(sum_2, 2)\n",
        "\n",
        "assert jnp.array_equal(sum_cols(jnp.array([[1, 2, 3], [4, 5, 6]])),\n",
        "                       jnp.array([5, 7, 9]))\n",
        "\n",
        "def signal_avg(t):\n",
        "  return lambda unused_theta: sum_cols(t) / shape(t)[rank(t) - 2]\n",
        "\n",
        "signal_avg_block = block(signal_avg, [])\n",
        "\n",
        "def fcn_block(b, m, d):\n",
        "  return stack_blocks([\n",
        "      recu_block(b, m, d),\n",
        "      recu_block(b, m, b)\n",
        "  ])\n",
        "\n",
        "morse_fcn = stack_blocks([\n",
        "    fcn_block(4, 3, 1),\n",
        "    fcn_block(8, 3, 4),\n",
        "    fcn_block(16, 3, 8),\n",
        "    fcn_block(26, 3, 16),\n",
        "    signal_avg_block\n",
        "])\n",
        "\n",
        "def init_shape(s, key):\n",
        "  if len(s) == 1:\n",
        "    return jnp.zeros(s)\n",
        "  elif len(s) == 2:\n",
        "    return random_tensor(0.0, 2.0 / s[1], s, key)\n",
        "  elif len(s) == 3:\n",
        "    return random_tensor(0.0, 2.0 / (s[1] * s[2]), s, key)\n",
        "\n",
        "def trained_morse(classifier, theta_shapes):\n",
        "  return model(classifier,\n",
        "               adam_gradient_descent(\n",
        "                   sampling_obj(l2_loss(classifier), morse_train_xs, morse_train_ys, jax.random.key(42)),\n",
        "                   init_theta(theta_shapes, jax.random.key(42))))\n",
        "\n",
        "def train_morse(network):\n",
        "  with hypers(alpha, 0.0005), hypers(revs, 20000), hypers(batch_size, 8), hypers(mu, 0.9), hypers(beta, 0.999):\n",
        "    return trained_morse(block_fn(network), block_ls(network))\n",
        "\n",
        "print(\"morse_fcn: accuracy\", accuracy(train_morse(morse_fcn), morse_test_xs, morse_test_ys))\n",
        "\n",
        "def skip(f, j):\n",
        "  return lambda t: lambda theta: f(t)(theta) + correlate(theta[j], t)\n",
        "\n",
        "def skip_block(ba, d, b):\n",
        "  shape_list = block_ls(ba)\n",
        "  return block(skip(block_fn(ba), len(shape_list)), shape_list + [[b, 1, d]])\n",
        "\n",
        "def residual_block(b, m, d):\n",
        "  return skip_block(fcn_block(b, m, d), d, b)\n",
        "\n",
        "morse_residual = stack_blocks([\n",
        "    residual_block(4, 3, 1),\n",
        "    residual_block(8, 3, 4),\n",
        "    residual_block(16, 3, 8),\n",
        "    residual_block(26, 3, 16),\n",
        "    signal_avg_block\n",
        "])\n",
        "\n",
        "print(\"morse_residual: accuracy\", accuracy(train_morse(morse_residual), morse_test_xs, morse_test_ys))"
      ],
      "metadata": {
        "id": "sVNlf4qpT5ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670eb7e8-e7f3-4e38-c016-e271a1a8f410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "morse_fcn: accuracy 0.94134617\n",
            "morse_residual: accuracy 0.9634615\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPS9NYHHEckGogtHsUi7o/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
